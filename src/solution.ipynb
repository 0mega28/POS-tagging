{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "file_append = []\n",
    "\n",
    "for subdir, dirs, files in os.walk(r'../Train-corpus'):\n",
    "    for filename in files:\n",
    "        filepath = subdir + os.sep + filename\n",
    "        mytree = ET.parse(filepath)\n",
    "        root = mytree.getroot()\n",
    "\n",
    "        # Handled mw tags\n",
    "        for element in root.iter('mw'):\n",
    "            mw_words = \"\"\n",
    "\n",
    "        # strip the text field\n",
    "            for words in element.iter('w'):\n",
    "                mw_words += words.text\n",
    "            tag = element.attrib.get('c5')\n",
    "            file_append.append(mw_words.strip() + \"_\" + tag)\n",
    "\n",
    "        # Handled w tags\n",
    "        for element in root.iter('w'):\n",
    "            word = element.text\n",
    "            tag = element.attrib.get('c5')\n",
    "            tag_list = tag.split('-')\n",
    "            for tags in tag_list:\n",
    "                file_append.append(word.strip() + \"_\" + tags)\n",
    "\n",
    "        # Handled c tags\n",
    "        for element in root.iter('c'):\n",
    "            file_append.append(element.text.strip() + \"_\" + element.attrib.get('c5'))\n",
    "\n",
    "\n",
    "# mw tags i.e. multiword there are tags init\n",
    "# c tags i.e. puctuations\n",
    "# if tag1-tag2 then word_tag1, word_tag2\n",
    "# Handle the spacing \n",
    "# Don't take words from hw tags"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "myDict = {}\n",
    "\n",
    "for word in file_append:\n",
    "    if (word in myDict):\n",
    "        myDict[word] += 1\n",
    "    else:\n",
    "        myDict[word] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "\n",
    "word_dict = {}\n",
    "tag_dict = {}\n",
    "\n",
    "for element in file_append:\n",
    "    temp = element.split(\"_\")\n",
    "    word = temp[0].strip()\n",
    "    tag = temp[1]\n",
    "\n",
    "    if (word in word_dict):\n",
    "        word_dict[word] += 1\n",
    "    else: \n",
    "        word_dict[word] = 1\n",
    "\n",
    "    if (tag in tag_dict):\n",
    "        tag_dict[tag] += 1\n",
    "    else: \n",
    "        tag_dict[tag] = 1\n",
    "\n",
    "word_dict_ordered = dict( sorted(word_dict.items(), key=operator.itemgetter(1),reverse=True))\n",
    "tag_dict_ordered = dict( sorted(tag_dict.items(), key=operator.itemgetter(1),reverse=True))"
   ]
  },
  {
   "source": [
    "probability_of_word_given_tag = {}\n",
    "\n",
    "# P(Word|Tag) = P(Word_Tag)/P(Tag) = Count(Word_Tag)/Count(Tag)\n",
    "\n",
    "for word in word_dict.keys():\n",
    "    for tag in tag_dict.keys():\n",
    "        temp = word+\"_\"+tag\n",
    "        temp1 = word+\"|\"+tag\n",
    "        if (temp in myDict):\n",
    "            probability_of_word_given_tag[temp1] = myDict[temp] / tag_dict[tag]\n",
    "        else:\n",
    "            probability_of_word_given_tag[temp1] = 0"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict( word ):\n",
    "    \n",
    "    if word not in word_dict:\n",
    "        return \"UNC\"\n",
    "    mx_p = -1\n",
    "    tag_gen = \"\"\n",
    "    for tags in tag_dict.keys():\n",
    "        word_given_tag = word + \"|\" + tags\n",
    "        P = 0\n",
    "        if word in word_dict:\n",
    "            P = (float(probability_of_word_given_tag[word_given_tag]) * int(\n",
    "                tag_dict[tags])) / int(word_dict[word])\n",
    "        if P > mx_p:\n",
    "            mx_p = P\n",
    "            tag_gen = tags\n",
    "    return tag_gen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "test_files = glob.glob(\"../Test-corpus/*/*.xml\")\n",
    "print(test_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ref = []\n",
    "tagged = []\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "mw_correct = 0\n",
    "mw_total = 0\n",
    "p_correct = 0\n",
    "p_total = 0\n",
    "\n",
    "for test_file in test_files:\n",
    "    mytree1 = ET.parse(test_file)\n",
    "    root1 = mytree1.getroot()\n",
    "\n",
    "    \"\"\"Normal words tag\"\"\"\n",
    "    for element in root1.iter('w'):\n",
    "        word = element.text.strip()\n",
    "        tag = element.attrib.get('c5')\n",
    "\n",
    "        tag_gen = predict(word)\n",
    "        if tag == tag_gen:\n",
    "            correct += 1\n",
    "\n",
    "        if tag.find('-') != -1:\n",
    "            if tag.split('-')[0] == tag_gen or tag.split('-')[1] == tag_gen:\n",
    "                correct += 1\n",
    "                ref.append(tag_gen)\n",
    "            else:\n",
    "                ref.append(tag)\n",
    "        else:\n",
    "            ref.append(tag)\n",
    "        total += 1\n",
    "        tagged.append(tag_gen)\n",
    "\n",
    "\n",
    "    \"\"\"Multi-words\"\"\"\n",
    "    for element in root1.iter(\"mw\"):\n",
    "        word = \"\"\n",
    "        for word_mw in element.iter('w'):\n",
    "            word += word_mw.text\n",
    "        if word[-1] == \" \":\n",
    "            word = word[0:-1]\n",
    "        tag = element.attrib.get('c5')\n",
    "        tag_gen = predict(word)\n",
    "        if tag == tag_gen:\n",
    "            mw_correct += 1\n",
    "\n",
    "        if tag.find('-') != -1:\n",
    "            if tag.split('-')[0] == tag_gen or tag.split('-')[1] == tag_gen:\n",
    "                mw_correct += 1\n",
    "                ref.append(tag_gen)\n",
    "            else:\n",
    "                ref.append(tag)\n",
    "        else:\n",
    "            ref.append(tag)\n",
    "        mw_total += 1\n",
    "        tagged.append(tag_gen)\n",
    "\n",
    "    \"\"\"Punctuations\"\"\"\n",
    "    for element in root1.iter(\"c\"):\n",
    "        try:\n",
    "            word = element.text.strip()\n",
    "            tag = element.attrib.get('c5')\n",
    "            tag_gen = predict(word)\n",
    "            if tag == tag_gen:\n",
    "                p_correct += 1\n",
    "\n",
    "            if tag.find('-') != -1:\n",
    "                if tag.split('-')[0] == tag_gen or tag.split('-')[1] == tag_gen:\n",
    "                    p_correct += 1\n",
    "                    ref.append(tag_gen)\n",
    "                else:\n",
    "                    ref.append(tag)\n",
    "            else:\n",
    "                ref.append(tag)\n",
    "            p_total += 1\n",
    "            tagged.append(tag_gen)\n",
    "        except:\n",
    "            print(\"\")\n",
    "\n",
    "correct += mw_correct + p_correct\n",
    "total += mw_total + p_total\n",
    "print(correct,total)\n",
    "print(correct/total)\n",
    "\n",
    "# Correct words: 3818421\n",
    "# Total words: 4159247\n",
    "# 0.9180558403961102"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nltk.metrics import ConfusionMatrix\n",
    "import sys \n",
    "\n",
    "stdoutOrigin=sys.stdout \n",
    "sys.stdout = open(\"../generatedFiles/Confusion_matrix.txt\", \"w\")\n",
    "cm = ConfusionMatrix(ref, tagged)\n",
    "print(cm)\n",
    "sys.stdout.close()\n",
    "sys.stdout=stdoutOrigin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter  \n",
    "labels = list(tag_dict.keys())\n",
    "labels.append('UNC')\n",
    "\n",
    "true_positives = Counter()\n",
    "false_negatives = Counter()\n",
    "false_positives = Counter()\n",
    "\n",
    "for i in labels:\n",
    "    for j in labels:\n",
    "        if i == j:\n",
    "            true_positives[i] += cm[i,j]\n",
    "        else:\n",
    "            false_negatives[i] += cm[i,j]\n",
    "            false_positives[j] += cm[i,j]\n",
    "\n",
    "print (\"TP:\", sum(true_positives.values()))\n",
    "print (\"FN:\", sum(false_negatives.values()))\n",
    "print (\"FP:\", sum(false_positives.values()))\n",
    "TP=sum(true_positives.values())\n",
    "FP=sum(false_positives.values())\n",
    "FN=sum(false_negatives.values())\n",
    "\n",
    "\n",
    "precision = TP / float(TP+FP)\n",
    "recall = TP / float(TP+FN)\n",
    "fscore = 2 * (precision * recall) / float(precision + recall)\n",
    "print( fscore , precision , recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "tag_csv=csv.reader(open(\"../generatedFiles/tag_freq.csv\",'r',encoding=\"utf8\"))\n",
    "Tag_list=[]\n",
    "for tags in tag_csv:\n",
    "    Tag_list.append(tags[0])\n",
    "# print(len(tag_list))\n",
    "tag_number={}\n",
    "tag_number['<S>']=0\n",
    "tag_number['<E>']=0\n",
    "i=1\n",
    "for tags in Tag_list:\n",
    "    tag_number[tags]=i\n",
    "    i+=1\n",
    "# print(temp_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "transition_matrix=np.zeros((62,62))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def increment(curr,prev):\n",
    "    if '-' in prev:\n",
    "        compound_prev=prev.split('-')\n",
    "        if '-' in curr:\n",
    "            compound_curr=curr.split('-')\n",
    "            transition_matrix[tag_number[compound_prev[0]]][tag_number[compound_curr[0]]]+=1\n",
    "            transition_matrix[tag_number[compound_prev[0]]][tag_number[compound_curr[1]]]+=1\n",
    "            transition_matrix[tag_number[compound_prev[1]]][tag_number[compound_curr[0]]]+=1\n",
    "            transition_matrix[tag_number[compound_prev[1]]][tag_number[compound_curr[1]]]+=1\n",
    "        else:\n",
    "            transition_matrix[tag_number[compound_prev[0]]][tag_number[curr]]+=1\n",
    "            transition_matrix[tag_number[compound_prev[1]]][tag_number[curr]]+=1\n",
    "    else:\n",
    "        if '-' in curr:\n",
    "            compound_curr=curr.split('-')\n",
    "            transition_matrix[tag_number[prev]][tag_number[compound_curr[0]]]+=1\n",
    "            transition_matrix[tag_number[prev]][tag_number[compound_curr[1]]]+=1\n",
    "        else:\n",
    "            transition_matrix[tag_number[prev]][tag_number[curr]]+=1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import xml.etree.ElementTree as ET \n",
    "files = glob.glob(\"../Train-corpus/*/*.xml\")\n",
    "for filepath in files:\n",
    "    # print(filepath)\n",
    "    root=ET.parse(filepath).getroot()\n",
    "    for s_tag in root.iter('s'):\n",
    "        prev='<S>'\n",
    "        curr=''\n",
    "        end='<E>'\n",
    "        for tags in s_tag:\n",
    "            if 'c5' not in tags.attrib:\n",
    "                for u_tag in tags:\n",
    "                    curr=u_tag.attrib.get('c5')\n",
    "                    increment(curr,prev)\n",
    "                    prev=curr\n",
    "            elif tags.tag == 'mw':\n",
    "                for w in tags.iter('w'):\n",
    "                    curr = w.attrib.get('c5')\n",
    "                    increment(curr, prev)\n",
    "                    prev = curr\n",
    "            else:\n",
    "                curr=tags.attrib.get('c5')\n",
    "                increment(curr,prev)\n",
    "                prev=curr\n",
    "        increment(end,prev)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[ 0. 34.  0. 71. 47. 15. 17. 32. 27. 56.  8.  4.  1.  0.  0. 12. 12. 10.\n  4.  1. 12. 15. 10.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.\n  4.  0.  0.  1.  1.  0.  0.  1.  0.  0.  7.  0.  0.  0.  1.  0.  0.  0.\n  0.  0.  0.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "print(transition_matrix[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in range(len(transition_matrix)):\n",
    "    s=np.sum(transition_matrix[row])\n",
    "    if s!=0.0:\n",
    "        for i in range(len(transition_matrix[row])):\n",
    "            transition_matrix[row][i]/=s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['NN1', 'PUN', 'AT0', 'PRP', 'AJ0', 'NN2', 'NP0', 'AV0', 'PNP', 'CJC', 'PRF', 'VVN', 'VVD', 'VVI', 'DT0', 'PUQ', 'VVB', 'CRD', 'TO0', 'VVG', 'CJS', 'DPS', 'VM0', 'VBD', 'VBZ', 'AVP', 'VVZ', 'CJT', 'POS', 'XX0', 'NN0', 'VBI', 'DTQ', 'VBB', 'VHD', 'ORD', 'VHZ', 'PUR', 'PUL', 'PNI', 'UNC', 'VHB', 'AVQ', 'VBN', 'PNQ', 'EX0', 'AJC', 'VHI', 'PNX', 'AJS', 'VDB', 'VDD', 'VBG', 'ITJ', 'VDI', 'ZZ0', 'VDZ', 'VHG', 'VDN', 'VHN', 'VDG']\n{'<S>': 0, '<E>': 0, 'NN1': 1, 'PUN': 2, 'AT0': 3, 'PRP': 4, 'AJ0': 5, 'NN2': 6, 'NP0': 7, 'AV0': 8, 'PNP': 9, 'CJC': 10, 'PRF': 11, 'VVN': 12, 'VVD': 13, 'VVI': 14, 'DT0': 15, 'PUQ': 16, 'VVB': 17, 'CRD': 18, 'TO0': 19, 'VVG': 20, 'CJS': 21, 'DPS': 22, 'VM0': 23, 'VBD': 24, 'VBZ': 25, 'AVP': 26, 'VVZ': 27, 'CJT': 28, 'POS': 29, 'XX0': 30, 'NN0': 31, 'VBI': 32, 'DTQ': 33, 'VBB': 34, 'VHD': 35, 'ORD': 36, 'VHZ': 37, 'PUR': 38, 'PUL': 39, 'PNI': 40, 'UNC': 41, 'VHB': 42, 'AVQ': 43, 'VBN': 44, 'PNQ': 45, 'EX0': 46, 'AJC': 47, 'VHI': 48, 'PNX': 49, 'AJS': 50, 'VDB': 51, 'VDD': 52, 'VBG': 53, 'ITJ': 54, 'VDI': 55, 'ZZ0': 56, 'VDZ': 57, 'VHG': 58, 'VDN': 59, 'VHN': 60, 'VDG': 61}\n"
     ]
    }
   ],
   "source": [
    "print(Tag_list)\n",
    "print(tag_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Viterbi(word_list):\n",
    "    pred_tag_list = []\n",
    "    prev_prob_list = []\n",
    "    is_start = True\n",
    "    for word in word_list:\n",
    "        curr_prob_list = np.zeros(61)\n",
    "        if is_start:\n",
    "            for i in range(61):\n",
    "                word_given_tag = word+\"|\"+Tag_list[i]\n",
    "                curr_prob_list[i] = transition_matrix[0][i+1]\n",
    "                curr_prob_list[i] *= probability_of_word_given_tag[word_given_tag]\n",
    "            is_start = False   \n",
    "        else:\n",
    "            for i in range(61):\n",
    "                word_given_tag = word+\"|\"+Tag_list[i]\n",
    "                for j in range(61):\n",
    "                    curr_prob_list[i] = max(curr_prob_list[i], prev_prob_list[j]*transition_matrix[j+1][i+1])\n",
    "                curr_prob_list[i] *= probability_of_word_given_tag[word_given_tag]\n",
    "        pred_tag = Tag_list[np.argmax(curr_prob_list)]\n",
    "        pred_tag_list.append(pred_tag)\n",
    "        prev_prob_list = curr_prob_list\n",
    "    return pred_tag_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "68 72 0.9444444444444444\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import xml.etree.ElementTree as ET \n",
    "# files = glob.glob(\"../Train-corpus/*/*.xml\")\n",
    "# for filepath in files:\n",
    "\n",
    "total = 0\n",
    "correct = 0\n",
    "# filepath = \"../Train-corpus/A1/A1A.xml\"\n",
    "filepath = \"./test2.xml\"\n",
    "root=ET.parse(filepath).getroot()\n",
    "for s_tag in root.iter('s'):\n",
    "    word_list = []\n",
    "    tag_list = []\n",
    "    for tags in s_tag:\n",
    "        if 'c5' not in tags.attrib:\n",
    "            for u_tag in tags:\n",
    "                curr_tag = u_tag.attrib.get('c5')\n",
    "                curr_word = u_tag.text.strip()\n",
    "                tag_list.append(curr_tag)\n",
    "                word_list.append(curr_word)\n",
    "        elif tags.tag == 'mw':\n",
    "            for w in tags.iter('w'):\n",
    "                curr_tag = w.attrib.get('c5')\n",
    "                curr_word = w.text.strip()\n",
    "                tag_list.append(curr_tag)\n",
    "                word_list.append(curr_word)\n",
    "        else:\n",
    "            curr_tag = tags.attrib.get('c5')\n",
    "            curr_word = tags.text.strip()\n",
    "            tag_list.append(curr_tag)\n",
    "            word_list.append(curr_word)\n",
    "\n",
    "    pred_tag_list = Viterbi(word_list)\n",
    "    for i in range(len(tag_list)):\n",
    "        curr_tag = tag_list[i]\n",
    "        if \"-\" in curr_tag:\n",
    "            mc_list = curr_tag.split(\"-\")\n",
    "            if mc_list[0] ==pred_tag_list[i] or mc_list[1] ==pred_tag_list[i]:\n",
    "                correct += 1\n",
    "        elif pred_tag_list[i] == tag_list[i]:\n",
    "           correct += 1\n",
    "        total += 1\n",
    "    \n",
    "print(correct, total, correct/total)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['PRP', 'AT0', 'AJ0', 'NN1', 'PUN', 'PNP', 'VHZ', 'VVN', 'AJ0', 'CJC', 'XX0', 'AJ0', 'PUN', 'CJC', 'PNP', 'VVZ', 'PRP', 'AT0', 'AJ0', 'NN2', 'PRP', 'AT0', 'AJ0', 'NP0', 'NN1', 'PRF', 'NN2', 'CJC', 'NP0', 'NN1', 'PRF', 'NN2', 'VVG', 'PRP', 'PUN', 'CJC', 'AT0', 'DT0', 'AJ0', 'NN2', 'PUN']\n['At', 'the', 'present', 'time', ',', 'it', 'has', 'become', 'attenuated', 'but', 'not', 'extinct', ',', 'and', 'it', 'continues', 'in', 'the', 'long', 'review-articles', 'in', 'the', 'new', 'York', 'Review', 'of', 'Books', 'and', 'London', 'Review', 'of', 'Books', 'according', 'to', ',', 'and', 'a', 'few', 'other', 'periodicals', '.']\n['PRP', 'AT0', 'AJ0', 'NN1', 'PUN', 'PNP', 'VHZ', 'VVN', 'AJ0', 'CJC', 'XX0', 'AJ0', 'PUN', 'CJC', 'PNP', 'VVZ', 'PRP', 'AT0', 'AJ0', 'NN2', 'PRP', 'AT0', 'AJ0', 'NP0', 'NN1', 'PRF', 'NN2', 'CJC', 'NP0', 'NN1', 'PRF', 'NN2', 'VVG', 'PRP', 'PUN', 'CJC', 'AT0', 'DT0', 'AJ0', 'NN2', 'PUN']\n"
     ]
    }
   ],
   "source": [
    "print(pred_tag_list)\n",
    "print(word_list)\n",
    "print(tag_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}